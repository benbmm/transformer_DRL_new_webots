#!/usr/bin/env python3
"""
å…­è¶³æ©Ÿå™¨äºº PPO + Transformer Webots æ§åˆ¶å™¨
å°ˆé–€ç”¨æ–¼è¨“ç·´ - ç°¡åŒ–ç‰ˆæœ¬
"""

import sys
import os
import time
import math
import numpy as np
import torch
import torch.nn as nn
from typing import Dict, Any, Optional, Type, Union, List
import json
from dataclasses import dataclass, field
from collections import deque

# Webots imports
from controller import Supervisor

# TensorBoard import
from torch.utils.tensorboard import SummaryWriter

try:
    import stable_baselines3 as sb3
    from stable_baselines3 import PPO
    from stable_baselines3.common.policies import ActorCriticPolicy
    from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
    from stable_baselines3.common.callbacks import BaseCallback
    from stable_baselines3.common.utils import set_random_seed
    from stable_baselines3.common.vec_env import DummyVecEnv
    from stable_baselines3.common.monitor import Monitor
    from stable_baselines3.common.callbacks import BaseCallback
    from stable_baselines3.common.utils import LinearSchedule
    from stable_baselines3.common.env_checker import check_env
    import gymnasium as gym
    from gymnasium import spaces
except ImportError as e:
    print(f'è«‹å®‰è£å¿…è¦å¥—ä»¶: pip install stable-baselines3[extra] gymnasium')
    sys.exit(1)

@dataclass
class HexapodConfig:
    """å…­è¶³æ©Ÿå™¨äººè¨“ç·´é…ç½® - çµ±ä¸€åƒæ•¸ç®¡ç†"""
    
    # === ç’°å¢ƒåƒæ•¸ ===
    max_episode_steps: int = 2048
    sequence_length: int = 100
    control_start_step: int = 100
    
    # === CPG åƒæ•¸ ===
    knee_clamp_positive: bool = True
    use_knee_signal_for_ankle: bool = True
    body_height_offset: float = 0.5
    
    # === çå‹µæ¬Šé‡ ===
    w_s: float = 1.0  # ç©©å®šæ€§çå‹µæ¬Šé‡
    w_c: float = 0.05  # æ§åˆ¶é‡çå‹µæ¬Šé‡
    
    # === Transformer æ¶æ§‹åƒæ•¸ ===
    transformer_features_dim: int = 6
    transformer_n_heads: int = 2
    transformer_n_layers: int = 3
    transformer_dropout: float = 0.1
    
    # === PPO è¶…åƒæ•¸ ===
    use_linear_learning_rate_decay: bool = False
    learning_rate_start: float = 3e-4
    learning_rate_end: float = 1e-5
    #fixed_learning_rate: float = 2.0633e-05
    fixed_learning_rate: float = 0.0003
    n_steps: int = 2048
    batch_size: int = 1024
    n_epochs: int = 10
    gamma: float = 0.98
    gae_lambda: float = 0.95
    clip_range: float = 0.1
    ent_coef: float = 0.05
    vf_coef: float = 0.5
    max_grad_norm: float = 0.5
    
    # === è¨“ç·´åƒæ•¸ ===
    total_timesteps: int = 100000000
    save_frequency_ratio: float = 0.05  # ç¸½æ­¥æ•¸çš„æ¯”ä¾‹
    random_seed: int = 42
    
    # === ç³»çµ±åƒæ•¸ ===
    tensorboard_log_dir: str = "./tensorboard_logs"
    model_save_dir: str = "./models"

    # === çå‹µåƒæ•¸ ===
    imbalance_threshold: float = 0.05  # éå¹³è¡¡é–¾å€¼ (roll/pitch abs > æ­¤å€¼)
    response_bonus: float = 0.1  # æ¯éš»æ­£ç¢ºå›æ‡‰è…³çš„çå‹µ
    response_penalty: float = -0.05  # æ¯éš»æœªå›æ‡‰è…³çš„æ‡²ç½°

    # === actionå™ªéŸ³åƒæ•¸ ===
    noise_probability: float = 0.05 # åŠ å…¥å™ªéŸ³çš„æ©Ÿç‡ï¼Œ0.05=5%
    noise_std: float = 0.1 # åŠ å…¥çš„å™ªéŸ³å€¼çš„é«˜æ–¯åˆ†å¸ƒçš„å¯¬(æ¨™æº–å·®)
    # === è¨ˆç®—å±¬æ€§æ–¹æ³• ===
    def get_save_frequency(self) -> int:
        """è¨ˆç®—å„²å­˜é »ç‡"""
        return int(self.total_timesteps * self.save_frequency_ratio)
    
    def get_net_arch(self) -> Dict[str, List[int]]:
        """ç²å–ç¶²è·¯æ¶æ§‹"""
        return dict(
            pi=[self.transformer_features_dim, self.transformer_features_dim], 
            vf=[self.transformer_features_dim, self.transformer_features_dim]
        )
    
    def get_transformer_kwargs(self) -> Dict[str, Any]:
        """ç²å– Transformer åƒæ•¸å­—å…¸"""
        return {
            'features_dim': self.transformer_features_dim,
            'n_heads': self.transformer_n_heads,
            'n_layers': self.transformer_n_layers,
            'sequence_length': self.sequence_length,
            'dropout': self.transformer_dropout
        }
    def get_learning_rate(self):
        """ç²å–å­¸ç¿’ç‡è¨­ç½®"""
        if self.use_linear_learning_rate_decay:
            return LinearSchedule(
                start=self.learning_rate_start,
                end=self.learning_rate_end,
                end_fraction=1.0
            )
        else:
            return self.fixed_learning_rate



class PositionalEncoding(nn.Module):
    """ä½ç½®ç·¨ç¢¼æ¨¡çµ„ - æ”¯æ´ batch_first"""
    
    def __init__(self, d_model: int, max_len: int = 500, batch_first: bool = True):
        super().__init__()
        self.batch_first = batch_first
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        if batch_first:
            # æ ¼å¼: [1, max_len, d_model] é©ç”¨æ–¼ [batch_size, seq_len, d_model]
            pe = pe.unsqueeze(0)  # [1, max_len, d_model]
        else:
            # æ ¼å¼: [max_len, 1, d_model] é©ç”¨æ–¼ [seq_len, batch_size, d_model]
            pe = pe.unsqueeze(0).transpose(0, 1)  # [max_len, 1, d_model]
        
        self.register_buffer('pe', pe)
    
    def forward(self, x):
        """
        Args:
            x: Tensor
            - å¦‚æœ batch_first=True: [batch_size, seq_len, embedding_dim]
            - å¦‚æœ batch_first=False: [seq_len, batch_size, embedding_dim]
        """
        if self.batch_first:
            # x: [batch_size, seq_len, embedding_dim]
            seq_len = x.size(1)
            return x + self.pe[:, :seq_len, :]
        else:
            # x: [seq_len, batch_size, embedding_dim]
            seq_len = x.size(0)
            return x + self.pe[:seq_len, :]


class TransformerFeaturesExtractor(BaseFeaturesExtractor):
    """
    è‡ªå®šç¾© Transformer ç‰¹å¾µæå–å™¨
    è™•ç†åºåˆ—æ•¸æ“šä¸¦è¼¸å‡ºç­–ç•¥ç¶²è·¯æ‰€éœ€çš„ç‰¹å¾µ
    """
    
    def __init__(self, observation_space, config: HexapodConfig):
        # å…ˆèª¿ç”¨çˆ¶é¡åˆå§‹åŒ–
        super().__init__(observation_space, config.transformer_features_dim)
        
        self.sequence_length = config.sequence_length
        self.state_dim = observation_space.shape[0] // config.sequence_length
        self._features_dim = config.transformer_features_dim
        print(f"observation_space.shape[0]={observation_space.shape[0]}\nsequence_length={self.sequence_length}\nstate_dim={self.state_dim}\nobservation_space.shape={observation_space.shape}")
        
        # è¼¸å…¥æŠ•å½±å±¤
        #self.input_projection = nn.Linear(self.state_dim, config.transformer_features_dim)
        
        # ä½ç½®ç·¨ç¢¼
        self.pos_encoding = PositionalEncoding(config.transformer_features_dim, config.sequence_length)
        
        # Transformer ç·¨ç¢¼å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=config.transformer_features_dim,
            nhead=config.transformer_n_heads,
            dim_feedforward=config.transformer_features_dim * 2,
            dropout=config.transformer_dropout,
            activation='relu',
            batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=config.transformer_n_layers)
        
        # è¼¸å‡ºæŠ•å½±å±¤
        #self.output_projection = nn.Linear(config.transformer_features_dim, config.transformer_features_dim)

        
        print(f"ğŸ¤– Transformer ç‰¹å¾µæå–å™¨åˆå§‹åŒ–:")
        print(f"   ğŸ“ åºåˆ—é•·åº¦: {self.sequence_length}")
        print(f"   ğŸ“Š ç‹€æ…‹ç¶­åº¦: {self.state_dim}")
        print(f"   ğŸ§  ç‰¹å¾µç¶­åº¦: {config.transformer_features_dim}")
        print(f"   ğŸ‘ï¸  æ³¨æ„åŠ›é ­æ•¸: {config.transformer_n_heads}")
        print(f"   ğŸ—ï¸  Transformerå±¤æ•¸: {config.transformer_n_layers}")
    
    def forward(self, observations: torch.Tensor) -> torch.Tensor:
        """
        Args:
            observations: [batch_size, sequence_length * state_dim]
        Returns:
            features: [batch_size, features_dim]
        """
        # print(f"ğŸ” TransformerFeaturesExtractor è¼¸å…¥å½¢ç‹€: {observations.shape}")
        batch_size = observations.shape[0]
        # print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {batch_size}")

        # é‡å¡‘è¼¸å…¥: [batch_size, seq_len * state_dim] -> [batch_size, seq_len, state_dim]
        x = observations.view(batch_size, self.sequence_length, self.state_dim)
        # print(f"ğŸ”„ é‡å¡‘å¾Œå½¢ç‹€: {x.shape}")

        # æŠ•å½±åˆ°ç‰¹å¾µç©ºé–“: [batch_size, seq_len, features_dim]
        #x = self.input_projection(x)
        # print(f"ğŸ“ è¼¸å…¥æŠ•å½±å¾Œå½¢ç‹€: {x.shape}")

        # åŠ å…¥ä½ç½®ç·¨ç¢¼
        x = self.pos_encoding(x)
        
        # é€šé Transformer ç·¨ç¢¼å™¨
        x = self.transformer_encoder(x)
        
        # å–æœ€å¾Œä¸€å€‹æ™‚é–“æ­¥çš„è¼¸å‡º: [batch_size, features_dim]
        x = x[:, -1, :]
        # print(f"ğŸ¯ æœ€çµ‚è¼¸å‡ºå½¢ç‹€: {x.shape}")
        
        # æœ€çµ‚æŠ•å½±
        #features = self.output_projection(x)
        features = x
        # print(f"âœ… ç‰¹å¾µå½¢ç‹€: {features.shape}")
        # print("-" * 50)  # åˆ†éš”ç·š
        
        return features


class TransformerActorCriticPolicy(ActorCriticPolicy):
    """
    è‡ªå®šç¾© Actor-Critic ç­–ç•¥ï¼Œä½¿ç”¨ Transformer ç‰¹å¾µæå–å™¨
    """
    
    def __init__(self, observation_space, action_space, lr_schedule, *args, **kwargs):
        # ç§»é™¤ config åƒæ•¸ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå› ç‚ºæˆ‘å€‘é€šé features_extractor_kwargs å‚³é
        kwargs.pop('config', None)  # å®‰å…¨ç§»é™¤ï¼Œé¿å…é‡è¤‡å‚³é
        
        # ç¢ºä¿ä½¿ç”¨æˆ‘å€‘çš„ TransformerFeaturesExtractor
        kwargs.setdefault('features_extractor_class', TransformerFeaturesExtractor)
        kwargs.setdefault('features_extractor_kwargs', {})
        
        super().__init__(
            observation_space,
            action_space,
            lr_schedule,
            *args,
            **kwargs
        )

class HexapodBalanceEnv(Supervisor, gym.Env):
    """
    å…­è¶³æ©Ÿå™¨äººå¹³è¡¡å¼·åŒ–å­¸ç¿’ç’°å¢ƒ
    ç›´æ¥åœ¨ Webots Controller ä¸­é‹è¡Œ
    """
    
    def __init__(self, config: HexapodConfig):
        super().__init__()
        
        # ç’°å¢ƒåƒæ•¸
        self.max_episode_steps = config.max_episode_steps
        self.sequence_length = config.sequence_length
        self.current_step = 0
        
        # CPGåƒæ•¸
        self.knee_clamp_positive = config.knee_clamp_positive
        self.use_knee_signal_for_ankle = config.use_knee_signal_for_ankle
        self.body_height_offset = config.body_height_offset
        self.control_start_step = config.control_start_step
        
        # çå‹µæ¬Šé‡
        self.w_s = config.w_s # ç©©å®šæ€§çå‹µæ¬Šé‡
        self.w_c = config.w_c # æ§åˆ¶é‡çå‹µæ¬Šé‡
        
        # å„²å­˜é…ç½®å¼•ç”¨ï¼ˆå¯é¸ï¼‰
        self.config = config

        # éš¨æ©Ÿå¹³å°æ—‹è½‰ç›¸é—œ
        self.random_platform_angle = 0.0  # ç•¶å‰episodeçš„éš¨æ©Ÿè§’åº¦
        # å¹³å°æ“ºå‹•è§’åº¦
        self.platform_angle=0.0

        self.prev_roll = 0.0  # ä¸Šä¸€æ­¥ roll
        self.prev_pitch = 0.0  # ä¸Šä¸€æ­¥ pitch
        self.prev_states = np.zeros(6, dtype=np.float32)  # ä¸Šä¸€æ­¥ 6 åˆ†é‡ç‹€æ…‹
        self.imbalance_threshold = config.imbalance_threshold
        self.response_bonus = config.response_bonus
        self.response_penalty = config.response_penalty

        #actionå™ªéŸ³ç›¸é—œ
        self.noise_probability=config.noise_probability
        self.noise_std=config.noise_std
        
        # Episodeçµ±è¨ˆï¼ˆç”¨æ–¼è¨˜éŒ„å¹³å‡å€¼ï¼‰
        self.episode_stats = {
            'stability_rewards': [],
            'control_rewards': [],
            'penalties': [],
            'rolls': [],
            'pitches': [],
            'distances_from_origin': []
        }
        
        self.spec = type('SimpleSpec', (), {'id': 'HexapodBalance-v0','max_episode_steps': self.max_episode_steps})()
        
        # ç‹€æ…‹å’Œå‹•ä½œç©ºé–“å®šç¾©
        self._setup_spaces()
        
        # Webotsè¨­ç½®
        self.timestep = int(self.getBasicTimeStep())
        self.motors = {}
        self.gps_device = None
        self.imu_device = None
        self.platform_motor_joint = None
        
        # ç‹€æ…‹åºåˆ—ç·©å­˜ï¼ˆç”¨æ–¼Transformerï¼‰
        self.state_sequence = deque(maxlen=self.sequence_length)
        
        # åˆå§‹åŒ–è¨­å‚™
        self._init_devices()
        
        print("âœ… å…­è¶³æ©Ÿå™¨äººå¹³è¡¡ç’°å¢ƒå·²åˆå§‹åŒ–ï¼ˆå¢å¼·ç‰ˆæœ¬ï¼‰")
        print(f"   ğŸ¯ ç©©å®šæ€§çå‹µæ¬Šé‡: {self.w_s}")
        print(f"   ğŸ® æ§åˆ¶é‡çå‹µæ¬Šé‡: {self.w_c}")

    def _setup_spaces(self):
        """è¨­ç½®ç‹€æ…‹å’Œå‹•ä½œç©ºé–“"""
        # å‹•ä½œç©ºé–“ï¼š6å€‹è†é—œç¯€çš„ä¿®æ­£é‡ [-1, 1]ï¼Œä½¿ç”¨[-1, 1]æ˜¯å®˜æ–¹æ¨è–¦è¦å°ç¨±ä»¥0ç‚ºä¸­å¿ƒ
        self.action_space = spaces.Box(
            low=-1.0, 
            high=1.0, 
            shape=(6,), 
            dtype=np.float32
        )
        
        # ç‹€æ…‹ç©ºé–“ï¼šåºåˆ—åŒ–çš„ç‹€æ…‹ [sequence_length * state_dim]
        single_state_dim = 6  # å…­å€‹è…³çš„æ–¹å‘åˆ†é‡
        sequence_dim = self.sequence_length * single_state_dim  # 50 * 6 = 300
        
        self.observation_space = spaces.Box(
            low=-4.0, 
            high=4.0, 
            shape=(sequence_dim,), 
            dtype=np.float32
        )
        
        # print(f"ğŸ“Š è§€å¯Ÿç©ºé–“ç¶­åº¦: {sequence_dim} (åºåˆ—é•·åº¦: {self.sequence_length} Ã— ç‹€æ…‹ç¶­åº¦: {single_state_dim})")
        # print(f"ğŸ® å‹•ä½œç©ºé–“ç¶­åº¦: {self.action_space.shape[0]}")

    def _init_devices(self):
        """åˆå§‹åŒ–Webotsè¨­å‚™"""
        try:
            self._init_motors()
            self._init_gps()
            self._init_imu()
            self._init_platform_motor()
        except Exception as e:
            print(f"âŒ è¨­å‚™åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def _init_motors(self):
        """åˆå§‹åŒ–æ©Ÿå™¨äººé¦¬é”"""
        leg_mapping = {
            1: ('R0', 'å³å‰è…¿'),
            2: ('R1', 'å³ä¸­è…¿'), 
            3: ('R2', 'å³å¾Œè…¿'),
            4: ('L2', 'å·¦å¾Œè…¿'),
            5: ('L1', 'å·¦ä¸­è…¿'),
            6: ('L0', 'å·¦å‰è…¿')
        }
        
        joint_names = ['0', '1', '2']
        
        for leg_idx in range(1, 7):
            if leg_idx not in leg_mapping:
                continue
                
            leg_name, _ = leg_mapping[leg_idx]
            self.motors[leg_idx] = {}
            
            for j, joint_name in enumerate(joint_names):
                joint_idx = j + 1
                motor_name = f"{leg_name}{joint_name}"
                
                try:
                    motor = self.getDevice(motor_name)
                    if motor is None:
                        continue
                    
                    motor.setPosition(0.0)
                    motor.setVelocity(motor.getMaxVelocity())
                    
                    self.motors[leg_idx][joint_idx] = motor
                    
                except Exception as e:
                    print(f"âŒ åˆå§‹åŒ–é¦¬é” {motor_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def _init_gps(self):
        """åˆå§‹åŒ–GPSæ„Ÿæ¸¬å™¨"""
        try:
            self.gps_device = self.getDevice("gps")
            if self.gps_device:
                self.gps_device.enable(self.timestep)
        except Exception as e:
            print(f"âŒ GPSåˆå§‹åŒ–å¤±æ•—: {e}")

    def _init_imu(self):
        """åˆå§‹åŒ–IMUæ„Ÿæ¸¬å™¨"""
        try:
            self.imu_device = self.getDevice("inertialunit1")
            if self.imu_device:
                self.imu_device.enable(self.timestep)
        except Exception as e:
            print(f"âŒ IMUåˆå§‹åŒ–å¤±æ•—: {e}")

    def _init_platform_motor(self):
        """åˆå§‹åŒ–å¹³å°é¦¬é”"""
        try:
            platform_node = self.getFromDef("experimental_platform")
            if platform_node is None:
                return
            
            children_field = platform_node.getField("children")
            children_count = children_field.getCount()
            
            for i in range(children_count):
                child = children_field.getMFNode(i)
                if child and child.getDef() == "platform_motor":
                    self.platform_motor_joint = child
                    break
                    
        except Exception as e:
            print(f"âŒ å¹³å°é¦¬é”åˆå§‹åŒ–å¤±æ•—: {e}")

    def _set_random_platform_rotation(self):
        """è¨­å®šéš¨æ©Ÿå¹³å°æ—‹è½‰è§’åº¦"""
        try:
            # ç”Ÿæˆ0-2Ï€ä¹‹é–“çš„éš¨æ©Ÿè§’åº¦
            self.random_platform_angle = np.random.uniform(0, 2 * np.pi)
            
            # ç²å– experimental_platform ç¯€é»
            platform_node = self.getFromDef("experimental_platform")
            if platform_node:
                # è¨­å®š Solid çš„ rotation å­—æ®µ: [0, 0, 1, random_angle]
                rotation_field = platform_node.getField("rotation")
                if rotation_field:
                    rotation_field.setSFRotation([0, 0, 1, self.random_platform_angle])
                    print(f"ğŸ”„ éš¨æ©Ÿå¹³å°æ—‹è½‰è§’åº¦: {self.random_platform_angle:.3f} å¼§åº¦ ({math.degrees(self.random_platform_angle):.1f}Â°)")
                        
        except Exception as e:
            print(f"âŒ è¨­å®šéš¨æ©Ÿå¹³å°æ—‹è½‰å¤±æ•—: {e}")

    def _get_imu_data(self):
        """è®€å–IMUæ•¸æ“š"""
        try:
            if self.imu_device:
                roll_pitch_yaw = self.imu_device.getRollPitchYaw()
                return roll_pitch_yaw[0], roll_pitch_yaw[1]
            else:
                return 0.0, 0.0
        except Exception as e:
            return 0.0, 0.0

    def _get_gps_data(self):
        """è®€å–GPSæ•¸æ“š"""
        try:
            if self.gps_device:
                position = self.gps_device.getValues()
                return position[0], position[1], position[2]
            else:
                return 0.0, 0.0, 0.0
        except Exception as e:
            return 0.0, 0.0, 0.0

    def _calculate_single_state(self):
        """è¨ˆç®—å–®æ­¥ç‹€æ…‹"""
        roll, pitch = self._get_imu_data()

        self.prev_roll = roll
        self.prev_pitch = pitch
        
        sqrt_half = math.sqrt(0.5)
        
        states = np.array([
            (pitch + roll) * sqrt_half,
            roll,
            (-pitch + roll) * sqrt_half,
            (-pitch - roll) * sqrt_half,
            -roll,
            (pitch - roll) * sqrt_half
        ], dtype=np.float32)
        
        return states

    def _get_sequence_observation(self):
        """ç²å–åºåˆ—è§€å¯Ÿ"""
        # ç²å–ç•¶å‰åºåˆ—é•·åº¦
        current_length = len(self.state_sequence)
        
        if current_length == 0:
            # å¦‚æœåºåˆ—ç‚ºç©ºï¼Œå…¨éƒ¨å¡«å……é›¶
            sequence = np.zeros((self.sequence_length, 6), dtype=np.float32)
        elif current_length < self.sequence_length:
            # å¦‚æœåºåˆ—ä¸å¤ é•·ï¼Œå‰é¢ç”¨é›¶å¡«å……
            padding_length = self.sequence_length - current_length
            padding = np.zeros((padding_length, 6), dtype=np.float32)
            
            # å°‡ç¾æœ‰åºåˆ—è½‰ç‚ºæ•¸çµ„
            existing_sequence = np.array(list(self.state_sequence), dtype=np.float32)
            
            # æ‹¼æ¥ï¼š[é›¶å¡«å……] + [ç¾æœ‰åºåˆ—]
            sequence = np.vstack([padding, existing_sequence])
        else:
            # åºåˆ—é•·åº¦è¶³å¤ ï¼Œç›´æ¥è½‰æ›
            sequence = np.array(list(self.state_sequence), dtype=np.float32)
        
        # å±•å¹³ç‚ºä¸€ç¶­æ•¸çµ„ [sequence_length * 6]
        flattened = sequence.flatten()
        
        # é™¤éŒ¯è³‡è¨Š
        """ if len(self.state_sequence) <= 2:  # åªåœ¨é–‹å§‹æ™‚å°å‡º
            print(f"ğŸ” åºåˆ—å½¢ç‹€: {sequence.shape}")
            print(f"ğŸ“Š å±•å¹³å¾Œå½¢ç‹€: {flattened.shape}")
            print(f"ğŸ“ˆ ç•¶å‰åºåˆ—é•·åº¦: {len(self.state_sequence)}") """
        
        return flattened

    def _calculate_reward(self, action):
        """è¨ˆç®—çå‹µå‡½æ•¸"""
        roll, pitch = self._get_imu_data()
        x, y, z = self._get_gps_data()
        
        # ç©©å®šæ€§çå‹µ
        stability_term = (abs(pitch) + abs(roll)) / 2
        r_s = math.exp(-(stability_term ** 2) / (0.1 ** 2))

        # 2. æ§åˆ¶é‡çå‹µï¼Œç•¶ç‹€æ…‹ä¸­å¤§æ–¼é›¶çš„åˆ†é‡å°æ‡‰çš„è…³çš„æ§åˆ¶é‡ä¹Ÿå¤§æ–¼é›¶ï¼Œçµ¦äºˆçå‹µ
        r_c = 0.0
        is_imbalanced = (abs(self.prev_roll) > self.imbalance_threshold) or (abs(self.prev_pitch) > self.imbalance_threshold)
        if is_imbalanced:
            positive_feet = np.where(self.prev_states > 0)[0]  # åˆ†é‡ >0 çš„è…³ç´¢å¼• (0-5)
            for foot_idx in positive_feet:
                if action[foot_idx] > 0:
                    r_c += self.response_bonus  # æ­£çå‹µ
                else:
                    r_c += self.response_penalty  # æ‡²ç½°
            if len(positive_feet) > 0:
                r_c /= len(positive_feet)  # å¹³å‡åŒ–ï¼Œé¿å…éå¤§
        # 3. æ‡²ç½°é …

        p = 0
        # è·Œå€’æ‡²ç½°
        if abs(pitch) >= 0.785 or abs(roll) >= 0.785:
            p += -1
        
        # é‚Šç•Œæ‡²ç½°
        if not (-1 <= x <= 1 and -1 <= y <= 1):
            p += -1
        
        # ç¸½çå‹µï¼šåŠ æ¬Šçµ„åˆ
        total_reward = self.w_s * r_s + self.w_c * r_c + p
        
        return total_reward, r_s, r_c, p

    def _is_done(self):
        """æª¢æŸ¥episodeæ˜¯å¦çµæŸ"""
        roll, pitch = self._get_imu_data()
        x, y, z = self._get_gps_data()
        
        if abs(pitch) >= 0.785 or abs(roll) >= 0.785:
            return True, True, "è·Œå€’"
        
        if not (-1 <= x <= 1 and -1 <= y <= 1):
            return True, True, "å‡ºç•Œ"
        
        if self.current_step >= self.max_episode_steps:
            return False, True, "è¶…æ™‚"
        
        return False, False, ""

    def _control_platform(self):
        """æ§åˆ¶å¹³å°é€²è¡Œæ­£å¼¦æ³¢é‹å‹•"""
        if not self.platform_motor_joint:
            return
        
        try:
            current_time = self.getTime()
            self.platform_angle = 0.2 * math.sin(1.0 * math.pi * current_time)
            
            joint_params_field = self.platform_motor_joint.getField("jointParameters")
            joint_params_node = joint_params_field.getSFNode()
            if joint_params_node:
                position_field = joint_params_node.getField("position")
                if position_field:
                    position_field.setSFFloat(self.platform_angle)
                    
        except Exception as e:
            print(f"å¹³å°æ§åˆ¶éŒ¯èª¤: {e}")

    def _apply_actions(self, rl_corrections):
        """æ‡‰ç”¨å‹•ä½œåˆ°æ©Ÿå™¨äºº"""
        #print(f"rl_corrections:{rl_corrections}\n")
        processed_signals = {}
        for leg_idx in range(1, 7):
            processed_signals[leg_idx] = {}
        
        for leg_idx in range(1, 7):
            if leg_idx not in self.motors:
                continue
            
            for joint_idx in range(1, 4):
                if joint_idx not in self.motors[leg_idx]:
                    continue
                
                
                if joint_idx == 2:  # è†é—œç¯€
                    motor_angle = 0.0 + rl_corrections[leg_idx - 1]
                else:
                    motor_angle = 0.0
                motor_angle = self._replace_ankle_with_knee_signal(motor_angle, leg_idx, joint_idx, processed_signals)
                motor_angle = self._process_special_joints(motor_angle, leg_idx, joint_idx)
                motor_angle = self._adjust_signal_direction(motor_angle, leg_idx, joint_idx)
                motor_angle = self._apply_height_offset(motor_angle, leg_idx, joint_idx)

                processed_signals[leg_idx][joint_idx] = motor_angle
                
                try:
                    if self.current_step >= self.control_start_step:
                        limited_angle = max(-1.0, min(1.0, motor_angle))
                        self.motors[leg_idx][joint_idx].setPosition(limited_angle)
                    else:
                        init_angle = self._replace_ankle_with_knee_signal(0.0, leg_idx, joint_idx, {})
                        init_angle = self._apply_height_offset(init_angle, leg_idx, joint_idx)
                        self.motors[leg_idx][joint_idx].setPosition(init_angle)
                except Exception as e:
                    print(f"è¨­å®šé¦¬é”è§’åº¦éŒ¯èª¤ (è…¿{leg_idx}, é—œç¯€{joint_idx}): {e}")

    def _replace_ankle_with_knee_signal(self, motor_angle, leg_idx, joint_idx, processed_signals):
        """å°‡è¸é—œç¯€è¨Šè™Ÿæ›¿æ›ç‚ºåŒéš»è…³è†é—œç¯€è™•ç†å¾Œçš„è¨Šè™Ÿ"""
        if joint_idx == 3 and self.use_knee_signal_for_ankle:
            if leg_idx in processed_signals and 2 in processed_signals[leg_idx]:
                knee_signal = processed_signals[leg_idx][2]
                return knee_signal * 1
            else:
                knee_angle = 0.0
                knee_angle = self._process_special_joints(knee_angle, leg_idx, 2)
                knee_angle = self._adjust_signal_direction(knee_angle, leg_idx, 2)
                knee_angle = self._apply_height_offset(knee_angle, leg_idx, 2)
                return knee_angle * 1
        return motor_angle

    def _process_special_joints(self, motor_angle, leg_idx, joint_idx):
        """è™•ç†ç‰¹æ®Šé—œç¯€"""
        if joint_idx == 2 and self.knee_clamp_positive and motor_angle <= 0:
            return 0.0
        
        if joint_idx == 3 and not self.use_knee_signal_for_ankle:
            if (leg_idx == 2 or leg_idx == 5) and motor_angle >= 0:
                return 0.0
        
        return motor_angle

    def _adjust_signal_direction(self, motor_angle, leg_idx, joint_idx):
        """èª¿æ•´è¨Šè™Ÿæ–¹å‘"""
        if not self.use_knee_signal_for_ankle and leg_idx <= 3 and joint_idx == 3:
            motor_angle = -motor_angle
        
        if leg_idx >= 4 and (joint_idx == 1 or joint_idx == 2):
            motor_angle = -motor_angle
        
        if not self.use_knee_signal_for_ankle and joint_idx == 3:
            if leg_idx in [1, 6, 2, 5]:
                motor_angle = -motor_angle
        
        return motor_angle

    def _apply_height_offset(self, motor_angle, leg_idx, joint_idx):
        """æ‡‰ç”¨æ©Ÿèº«é«˜åº¦åç§»"""
        should_apply_offset = (
            joint_idx == 2 or
            (joint_idx == 3 and not self.use_knee_signal_for_ankle)
        )
        
        if should_apply_offset:
            offset_direction = -1 if leg_idx <= 3 else 1
            return motor_angle + (self.body_height_offset * offset_direction)
        
        return motor_angle

    def _record_episode_stats(self, stability_reward, control_reward, penalty, roll, pitch, x, y):
        """è¨˜éŒ„episodeçµ±è¨ˆæ•¸æ“š"""
        # è¨ˆç®—èˆ‡åŸé»çš„è·é›¢
        distance_from_origin = math.sqrt(x**2 + y**2)
        
        self.episode_stats['stability_rewards'].append(stability_reward)
        self.episode_stats['control_rewards'].append(control_reward)
        self.episode_stats['penalties'].append(penalty)
        self.episode_stats['rolls'].append(abs(roll))  # è¨˜éŒ„çµ•å°å€¼
        self.episode_stats['pitches'].append(abs(pitch))  # è¨˜éŒ„çµ•å°å€¼
        self.episode_stats['distances_from_origin'].append(distance_from_origin)

    def _get_episode_averages(self):
        """è¨ˆç®—episodeå¹³å‡å€¼"""
        if not self.episode_stats['stability_rewards']:
            return {}
        
        return {
            'avg_stability_reward': np.mean(self.episode_stats['stability_rewards']),
            'avg_control_reward': np.mean(self.episode_stats['control_rewards']),
            'avg_penalty': np.mean(self.episode_stats['penalties']),
            'avg_abs_roll': np.mean(self.episode_stats['rolls']),  # çµ•å°å€¼çš„å¹³å‡
            'avg_abs_pitch': np.mean(self.episode_stats['pitches']),  # çµ•å°å€¼çš„å¹³å‡
            'avg_distance_from_origin': np.mean(self.episode_stats['distances_from_origin']),
            'platform_angle': self.random_platform_angle
        }

    def _reset_episode_stats(self):
        """é‡ç½®episodeçµ±è¨ˆæ•¸æ“š"""
        for key in self.episode_stats:
            self.episode_stats[key].clear()

    def reset(self, seed=None, options=None):
        """é‡ç½®ç’°å¢ƒ"""
        if seed is not None:
            np.random.seed(seed)
        
        print("ğŸ”„ é‡ç½®ç’°å¢ƒ...")
        
        # é‡ç½®æ¨¡æ“¬
        self.simulationResetPhysics()
        self.simulationReset()
        super().step(self.timestep)
        
        # é‡ç½®è¨ˆæ•¸å™¨å’Œç‹€æ…‹åºåˆ—
        self.current_step = 0
        self.state_sequence.clear()

        self.prev_roll = 0.0
        self.prev_pitch = 0.0
        self.prev_states = np.zeros(6, dtype=np.float32)
        
        # é‡ç½®episodeçµ±è¨ˆ
        self._reset_episode_stats()
        
        # é‡æ–°åˆå§‹åŒ–è¨­å‚™
        self._init_devices()
        # è¨­å®šéš¨æ©Ÿå¹³å°æ—‹è½‰
        self._set_random_platform_rotation()
        
        # åŸ·è¡Œå¹¾æ­¥ä»¥ç©©å®šç³»çµ±
        for _ in range(3):
            super().step(self.timestep)
        
        # ç²å–åˆå§‹åºåˆ—è§€å¯Ÿ
        initial_obs = self._get_sequence_observation()
        
        info = {
            'step': self.current_step,
            'imu_data': self._get_imu_data(),
            'gps_data': self._get_gps_data(),
            'stability_reward': 0.0,
            'control_reward': 0.0,
            'penalty': 0.0,
            'reason': '',
            'roll': 0.0,
            'pitch': 0.0,
            'position_x': 0.0,
            'platform_angle': self.random_platform_angle
        }
        
        return initial_obs, info

    def step(self, action):
        """åŸ·è¡Œä¸€æ­¥å‹•ä½œ"""
        action = np.array(action, dtype=np.float32)
        action = np.clip(action, self.action_space.low, self.action_space.high)
        
        # æ§åˆ¶å¹³å°é‹å‹•
        self._control_platform()
        
        # æ‡‰ç”¨å‹•ä½œåˆ°æ©Ÿå™¨äººï¼Œæ·»åŠ éš¨æ©Ÿå™ªéŸ³ä»¥å¢å¼·æ¢ç´¢
        if np.random.random() < self.noise_probability:
            #æ·»åŠ é«˜æ–¯å™ªéŸ³
            action += np.random.normal(0, self.noise_std, size=action.shape)
            action = np.clip(action, -1, 1)
        self._apply_actions(action)
        
        # åŸ·è¡Œç‰©ç†æ­¥é©Ÿ
        
        super().step(self.timestep)
        
        # æ›´æ–°æ­¥æ•¸
        self.current_step += 1
        
        # æ›´æ–°ç‹€æ…‹åºåˆ—
        current_state = self._calculate_single_state()
        self.state_sequence.append(current_state)
        self.prev_states=current_state
        
        # ç²å–æ–°çš„åºåˆ—è§€å¯Ÿ
        new_obs = self._get_sequence_observation()
        # é™¤éŒ¯ï¼šå°å‡ºè§€å¯Ÿå½¢ç‹€
        """ if self.current_step % 100 == 0:  # æ¯100æ­¥å°ä¸€æ¬¡
            print(f"ğŸ” ç’°å¢ƒè§€å¯Ÿå½¢ç‹€: {new_obs.shape}")
            print(f"ğŸ“Š è§€å¯Ÿæ•¸å€¼ç¯„åœ: [{new_obs.min():.3f}, {new_obs.max():.3f}]") """
        
        # è¨ˆç®—çå‹µï¼ˆåŒ…å«æ§åˆ¶é‡çå‹µï¼‰
        reward, stability_reward, control_reward, penalty = self._calculate_reward(action)
        
        # æª¢æŸ¥æ˜¯å¦çµæŸ
        terminated, truncated, reason = self._is_done()
        # ç²å–ç•¶å‰ç‹€æ…‹æ•¸æ“š
        roll, pitch = self._get_imu_data()
        x, y, z = self._get_gps_data()

        # è¨˜éŒ„episodeçµ±è¨ˆ
        self._record_episode_stats(stability_reward, control_reward, penalty, roll, pitch, x, y)
        
        info = {
            'stability_reward': float(stability_reward),
            'control_reward': float(control_reward),
            'penalty': float(penalty),
            'step': self.current_step,
            'reason': reason,
            'imu_data': self._get_imu_data(),
            'gps_data': self._get_gps_data(),
            'roll': float(roll),
            'pitch': float(pitch),
            'position_x': float(x),
            'platform_angle': self.random_platform_angle
        }
        
        # å¦‚æœepisodeçµæŸï¼Œæ·»åŠ å¹³å‡å€¼åˆ°info
        if terminated or truncated:
            episode_averages = self._get_episode_averages()
            info.update(episode_averages)

        # æ¯100æ­¥æ‰“å°é€²åº¦
        if self.current_step % 100 == 0:
            print(f"æ­¥æ•¸: {self.current_step}, ç¸½çå‹µ: {reward:.3f}, "
                f"ç©©å®š: {stability_reward:.3f}, æ§åˆ¶: {control_reward:.3f}, "
                f"å§¿æ…‹: roll={roll:.3f}, pitch={pitch:.3f}")
        
        return new_obs, float(reward), terminated, truncated, info

    def close(self):
        """é—œé–‰ç’°å¢ƒ"""
        print("ğŸ‘‹ é—œé–‰ç’°å¢ƒ...")


class WebotsPPOController:
    """
    åœ¨ Webots ä¸­é‹è¡Œçš„ PPO è¨“ç·´æ§åˆ¶å™¨
    """
    
    def __init__(self, config: HexapodConfig):
        print("ğŸš€ åˆå§‹åŒ– Webots PPO è¨“ç·´æ§åˆ¶å™¨")
        
        # è¨­ç½®éš¨æ©Ÿç¨®å­
        set_random_seed(config.random_seed)
        
        # å‰µå»ºç’°å¢ƒ
        self.env = HexapodBalanceEnv(config)

        print("ğŸ” æª¢æŸ¥ç’°å¢ƒæ˜¯å¦ç¬¦åˆ Gym API æ¨™æº–...")
        try:
            check_env(self.env, warn=True, skip_render_check=True)
            print("âœ… ç’°å¢ƒæª¢æŸ¥é€šéï¼ç¬¦åˆ Gym API æ¨™æº–")
        except Exception as e:
            print(f"âŒ ç’°å¢ƒæª¢æŸ¥å¤±æ•—: {e}")
            print("ğŸ”§ è«‹ä¿®æ­£ç’°å¢ƒå¯¦ä½œå¾Œå†ç¹¼çºŒè¨“ç·´")
            raise
        
        # è¨“ç·´åƒæ•¸
        self.total_timesteps = config.total_timesteps
        self.save_freq = config.get_save_frequency()
        
        # å‰µå»ºå¸¶ç·¨è™Ÿçš„è¨“ç·´è³‡æ–™å¤¾
        self.training_id = self._get_next_training_id()
        self.training_folder = f"training_{self.training_id:03d}"
        self.model_save_path = os.path.join(config.model_save_dir, self.training_folder)
        self.tensorboard_path = os.path.join(config.tensorboard_log_dir, self.training_folder)

        self.config = config
        
        # ç¢ºä¿å„²å­˜è·¯å¾‘å­˜åœ¨
        os.makedirs(self.model_save_path, exist_ok=True)
        os.makedirs(self.tensorboard_path, exist_ok=True)
        
        print(f"ğŸ“ è¨“ç·´è³‡æ–™å¤¾: {self.training_folder}")
        print(f"ğŸ’¾ æ¨¡å‹å„²å­˜è·¯å¾‘: {self.model_save_path}")
        print(f"ğŸ“Š TensorBoardè·¯å¾‘: {self.tensorboard_path}")
        
        # å‰µå»ºæ¨¡å‹
        self._create_model()
        
        # è¨“ç·´çµ±è¨ˆ
        self.episode_count = 0
        self.total_steps = 0
        self.episode_rewards = []
        self.current_episode_reward = 0

        # TensorBoard Writerï¼ˆåœ¨ callback ä¸­åˆå§‹åŒ–ï¼‰
        self.tb_writer = None
        
        # ä¿å­˜è¨“ç·´é…ç½®
        self._save_training_config()
        
        print("âœ… æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")

    def _get_next_training_id(self):
        """ç²å–ä¸‹ä¸€å€‹è¨“ç·´ç·¨è™Ÿ"""
        base_dirs = ["./models", "./tensorboard_logs"]
        max_id = 0
        
        for base_dir in base_dirs:
            if os.path.exists(base_dir):
                for folder_name in os.listdir(base_dir):
                    if folder_name.startswith("training_"):
                        try:
                            # æå–ç·¨è™Ÿ training_001 -> 1
                            folder_id = int(folder_name.split("_")[1])
                            max_id = max(max_id, folder_id)
                        except (ValueError, IndexError):
                            continue
        
        next_id = max_id + 1
        print(f"ğŸ”¢ ä¸‹ä¸€å€‹è¨“ç·´ç·¨è™Ÿ: {next_id}")
        return next_id

    def _save_training_config(self):
        """ä¿å­˜è¨“ç·´é…ç½®åˆ°æª”æ¡ˆ"""
        import json
        from datetime import datetime
        
        config = {
            "training_id": self.training_id,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_timesteps": self.total_timesteps,
            "save_frequency": self.save_freq,
            "environment": {
                "max_episode_steps": self.env.max_episode_steps,
                "sequence_length": self.env.sequence_length,
                "knee_clamp_positive": self.env.knee_clamp_positive,
                "use_knee_signal_for_ankle": self.env.use_knee_signal_for_ankle,
                "body_height_offset": self.env.body_height_offset,
                "control_start_step": self.env.control_start_step,
                "stability_reward_weight": self.env.w_s,
                "control_reward_weight": self.env.w_c
            },
            "gpu_info": {
                "cuda_available": torch.cuda.is_available(),
                "device_name": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU",
                "pytorch_version": torch.__version__
            }
        }
        
        config_path = os.path.join(self.model_save_path, "training_config.json")
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“ è¨“ç·´é…ç½®å·²ä¿å­˜: {config_path}")

    def _create_model(self):
        """å‰µå»º PPO æ¨¡å‹"""
        print("ğŸ¤– å‰µå»º PPO æ¨¡å‹...")
        
        # æª¢æŸ¥ GPU å¯ç”¨æ€§
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {device}")
        
        if device == 'cuda':
            print(f"   GPU åç¨±: {torch.cuda.get_device_name(0)}")
            print(f"   GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

        lr_schedule = self.config.get_learning_rate()
        
        # å‰µå»ºç­–ç•¥åƒæ•¸
        policy_kwargs = {
            'features_extractor_class': TransformerFeaturesExtractor,
            'features_extractor_kwargs': {'config': self.config},  # å‚³éé…ç½®
            'net_arch': self.config.get_net_arch()
        }
        
        # å‰µå»ºå‘é‡åŒ–ç’°å¢ƒ
        self.vec_env = DummyVecEnv([lambda: Monitor(self.env)])
        
        # å‰µå»º PPO æ¨¡å‹
        """ self.model = PPO(
            TransformerActorCriticPolicy,
            self.vec_env,
            learning_rate=lr_schedule,
            n_steps=4096,  
            batch_size=2048,  
            n_epochs=10,
            gamma=0.99,
            gae_lambda=0.95,
            clip_range=0.2,
            ent_coef=0.02,
            vf_coef=0.5,
            max_grad_norm=0.5,
            policy_kwargs=policy_kwargs,
            verbose=1,
            device=device,  # è‡ªå‹•é¸æ“‡æœ€ä½³è¨­å‚™
            tensorboard_log=self.tensorboard_path  # ä½¿ç”¨ç·¨è™Ÿè³‡æ–™å¤¾
        ) """
        self.model = PPO(
            TransformerActorCriticPolicy,
            self.vec_env,
            learning_rate=lr_schedule,
            n_steps=self.config.n_steps,
            batch_size=self.config.batch_size,
            n_epochs=self.config.n_epochs,
            gamma=self.config.gamma,
            gae_lambda=self.config.gae_lambda,
            clip_range=self.config.clip_range,
            ent_coef=self.config.ent_coef,
            vf_coef=self.config.vf_coef,
            max_grad_norm=self.config.max_grad_norm,
            policy_kwargs=policy_kwargs,
            verbose=1,
            device=device,
            tensorboard_log=self.tensorboard_path
        )
        print("=== ç­–ç•¥æ¶æ§‹ ===")
        print(self.model.policy)
        
        print(f"ğŸ§  æ¨¡å‹å·²å‰µå»ºï¼Œåƒæ•¸æ•¸é‡: {sum(p.numel() for p in self.model.policy.parameters() if p.requires_grad)}")
        print(f"ğŸ’¾ æ¨¡å‹è¨­å‚™: {next(self.model.policy.parameters()).device}")

    def run(self):
        """ä¸»è¨“ç·´å¾ªç’°"""
        print("ğŸƒ é–‹å§‹è¨“ç·´...")
        print("-" * 60)
        
        try:
            # é–‹å§‹è¨“ç·´
            self.model.learn(
                total_timesteps=self.total_timesteps,
                callback=self._training_callback,
                log_interval=1,
                reset_num_timesteps=False
            )
            
            print("âœ… è¨“ç·´å®Œæˆï¼")
            
            # å„²å­˜æœ€çµ‚æ¨¡å‹
            final_model_path = os.path.join(self.model_save_path, "ppo_hexapod_final")
            self.model.save(final_model_path)
            print(f"ğŸ’¾ æœ€çµ‚æ¨¡å‹å·²å„²å­˜: {final_model_path}")
            
        except KeyboardInterrupt:
            print("\nâ¹ï¸  è¨“ç·´è¢«ç”¨æˆ¶ä¸­æ–·")
            
            # å„²å­˜ä¸­æ–·æ™‚çš„æ¨¡å‹
            interrupt_model_path = os.path.join(self.model_save_path, "ppo_hexapod_interrupted")
            self.model.save(interrupt_model_path)
            print(f"ğŸ’¾ ä¸­æ–·æ¨¡å‹å·²å„²å­˜: {interrupt_model_path}")
        
        except Exception as e:
            print(f"âŒ è¨“ç·´éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            
            # å„²å­˜éŒ¯èª¤æ™‚çš„æ¨¡å‹
            error_model_path = os.path.join(self.model_save_path, "ppo_hexapod_error")
            self.model.save(error_model_path)
            print(f"ğŸ’¾ éŒ¯èª¤æ¨¡å‹å·²å„²å­˜: {error_model_path}")
            raise
        
        finally:
            # æ¸…ç†è³‡æº
            if hasattr(self, 'tb_writer') and self.tb_writer:
                self.tb_writer.close()
                print("ğŸ“Š TensorBoard Writer å·²é—œé–‰")
            self.env.close()
            print("ğŸ§¹ è³‡æºæ¸…ç†å®Œæˆ")

    def _training_callback(self, locals_, globals_):
        """æ•´åˆTensorBoardçš„è¨“ç·´å›èª¿å‡½æ•¸"""
        self.total_steps = locals_['self'].num_timesteps
        
        # åˆå§‹åŒ– TensorBoard Writer
        if not hasattr(self, 'tb_writer') or self.tb_writer is None:
            self.tb_writer = SummaryWriter(os.path.join(self.tensorboard_path, "detailed_logs"))
            print(f"ğŸ“Š TensorBoard Writer å·²åˆå§‹åŒ–: {self.tensorboard_path}")
        
        # è¨˜éŒ„è¨“ç·´æŒ‡æ¨™
        if len(locals_['infos']) > 0:
            for info in locals_['infos']:
                if 'episode' in info:
                    episode_reward = info['episode']['r']
                    episode_length = info['episode']['l']
                    
                    # è¨˜éŒ„åˆ° TensorBoard
                    self.tb_writer.add_scalar('Episode/Reward', episode_reward, self.total_steps)
                    self.tb_writer.add_scalar('Episode/Length', episode_length, self.total_steps)
                    
                                        # è¨˜éŒ„episodeå¹³å‡å€¼ï¼ˆä¿®æ­£å¾Œï¼‰
                    if 'avg_stability_reward' in info:
                        self.tb_writer.add_scalar('Environment/Avg_Stability_Reward', info['avg_stability_reward'], self.total_steps)
                    if 'avg_control_reward' in info:
                        self.tb_writer.add_scalar('Environment/Avg_Control_Reward', info['avg_control_reward'], self.total_steps)
                    if 'avg_penalty' in info:
                        self.tb_writer.add_scalar('Environment/Avg_Penalty', info['avg_penalty'], self.total_steps)
                    if 'avg_abs_roll' in info:
                        self.tb_writer.add_scalar('Environment/Avg_Abs_Roll', info['avg_abs_roll'], self.total_steps)
                    if 'avg_abs_pitch' in info:
                        self.tb_writer.add_scalar('Environment/Avg_Abs_Pitch', info['avg_abs_pitch'], self.total_steps)
                    if 'avg_distance_from_origin' in info:
                        self.tb_writer.add_scalar('Environment/Avg_Distance_From_Origin', info['avg_distance_from_origin'], self.total_steps)
                    if 'platform_angle' in info:
                        self.tb_writer.add_scalar('Environment/Platform_Angle', info['platform_angle'], self.total_steps)
                    
                    # è¨˜éŒ„çå‹µåˆ†è§£ï¼ˆä¿®æ­£å¾Œï¼‰
                    if 'avg_stability_reward' in info and 'avg_control_reward' in info:
                        total_reward_components = (
                            self.env.w_s * info['avg_stability_reward'] + 
                            self.env.w_c * info['avg_control_reward'] + 
                            info.get('avg_penalty', 0)
                        )
                        self.tb_writer.add_scalar('Reward/Total_Components', total_reward_components, self.total_steps)
                        self.tb_writer.add_scalar('Reward/Stability_Weighted', self.env.w_s * info['avg_stability_reward'], self.total_steps)
                        self.tb_writer.add_scalar('Reward/Control_Weighted', self.env.w_c * info['avg_control_reward'], self.total_steps)
                    
                    self.episode_rewards.append(episode_reward)
                    self.episode_count += 1
                    
                    print(f"ğŸ“ˆ Episode {self.episode_count} å®Œæˆ: ç¸½çå‹µ={episode_reward:.3f}, é•·åº¦={episode_length}")
                    if 'avg_stability_reward' in info:
                        print(f"   å¹³å‡ç©©å®šçå‹µ: {info['avg_stability_reward']:.3f}")
                    if 'avg_control_reward' in info:
                        print(f"   å¹³å‡æ§åˆ¶çå‹µ: {info['avg_control_reward']:.3f}")
                    if 'avg_abs_roll' in info and 'avg_abs_pitch' in info:
                        print(f"   å¹³å‡çµ•å°å§¿æ…‹: roll={info['avg_abs_roll']:.3f}, pitch={info['avg_abs_pitch']:.3f}")
                    if 'avg_distance_from_origin' in info:
                        print(f"   å¹³å‡è·é›¢åŸé»: {info['avg_distance_from_origin']:.3f}")
                    if 'platform_angle' in info:
                        print(f"   å¹³å°è§’åº¦: {math.degrees(info['platform_angle']):.1f}Â°")
                    
                    # è¨ˆç®—å¹³å‡çå‹µ
                    if len(self.episode_rewards) >= 10:
                        avg_reward = np.mean(self.episode_rewards[-10:])
                        self.tb_writer.add_scalar('Episode/Average_Reward_10', avg_reward, self.total_steps)
                        print(f"ğŸ“Š æœ€è¿‘10å€‹episodeå¹³å‡çå‹µ: {avg_reward:.3f}")
        
        # è¨˜éŒ„å­¸ç¿’æŒ‡æ¨™
        if hasattr(locals_['self'], 'logger') and locals_['self'].logger.name_to_value:
            for key, value in locals_['self'].logger.name_to_value.items():
                if any(keyword in key.lower() for keyword in ['loss', 'entropy', 'kl', 'value', 'policy']):
                    self.tb_writer.add_scalar(f'Training/{key}', value, self.total_steps)
        
        # å®šæœŸå„²å­˜æ¨¡å‹
        if self.total_steps % self.save_freq == 0 and self.total_steps > 0:
            model_path = os.path.join(self.model_save_path, f"ppo_hexapod_{self.total_steps}")
            self.model.save(model_path)
            print(f"ğŸ’¾ æ¨¡å‹å·²å„²å­˜: {model_path} (æ­¥æ•¸: {self.total_steps})")
            
            # é¡¯ç¤º GPU è¨˜æ†¶é«”ç”¨é‡ï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
            if torch.cuda.is_available():
                memory_allocated = torch.cuda.memory_allocated() / 1024**3
                memory_reserved = torch.cuda.memory_reserved() / 1024**3
                print(f"ğŸ“Š GPU è¨˜æ†¶é«”: {memory_allocated:.2f} GB / {memory_reserved:.2f} GB")
                
                # è¨˜éŒ„ GPU è¨˜æ†¶é«”ä½¿ç”¨åˆ° TensorBoard
                self.tb_writer.add_scalar('System/GPU_Memory_Allocated_GB', memory_allocated, self.total_steps)
                self.tb_writer.add_scalar('System/GPU_Memory_Reserved_GB', memory_reserved, self.total_steps)
        
        # å¼·åˆ¶åˆ·æ–° TensorBoard å¯«å…¥
        if self.tb_writer:
            self.tb_writer.flush()
        
        return True


def check_gpu_requirements():
    """æª¢æŸ¥ GPU éœ€æ±‚å’Œç’°å¢ƒ"""
    print("ğŸ” æª¢æŸ¥ GPU ç’°å¢ƒ...")
    
    # æª¢æŸ¥ PyTorch CUDA æ”¯æ´
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"cuDNN ç‰ˆæœ¬: {torch.backends.cudnn.version()}")
        print(f"GPU æ•¸é‡: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"GPU {i}: {props.name}")
            print(f"   è¨˜æ†¶é«”: {props.total_memory / 1024**3:.1f} GB")
            print(f"   è¨ˆç®—èƒ½åŠ›: {props.major}.{props.minor}")
        
        # æ¸¬è©¦ GPU è¨˜æ†¶é«”
        try:
            test_tensor = torch.randn(1000, 1000).cuda()
            print("âœ… GPU è¨˜æ†¶é«”æ¸¬è©¦é€šé")
            del test_tensor
            torch.cuda.empty_cache()
        except Exception as e:
            print(f"âŒ GPU è¨˜æ†¶é«”æ¸¬è©¦å¤±æ•—: {e}")
            return False
            
        return True
    else:
        print("âš ï¸  GPU ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨ CPU")
        print("å»ºè­°å®‰è£æ”¯æ´ CUDA çš„ PyTorch ç‰ˆæœ¬:")
        print("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        return False


def optimize_gpu_settings():
    """å„ªåŒ– GPU è¨­å®š"""
    if torch.cuda.is_available():
        print("âš™ï¸  å„ªåŒ– GPU è¨­å®š...")
        
        # å•Ÿç”¨ cuDNN è‡ªå‹•èª¿å„ª
        torch.backends.cudnn.benchmark = True
        print("âœ… cuDNN benchmark å·²å•Ÿç”¨")
        
        # è¨­å®šè¨˜æ†¶é«”åˆ†é…ç­–ç•¥
        torch.cuda.empty_cache()
        print("âœ… GPU è¨˜æ†¶é«”å·²æ¸…ç©º")
        
        # é¡¯ç¤ºåˆå§‹è¨˜æ†¶é«”ä½¿ç”¨
        if torch.cuda.is_available():
            memory_allocated = torch.cuda.memory_allocated() / 1024**3
            memory_reserved = torch.cuda.memory_reserved() / 1024**3
            print(f"ğŸ“Š GPU è¨˜æ†¶é«”ä½¿ç”¨: {memory_allocated:.2f} GB / {memory_reserved:.2f} GB")


def main():
    """
    Webots Controller ä¸»å…¥å£é» - å°ˆé–€ç”¨æ–¼è¨“ç·´
    """
    print("=" * 60)
    print("ğŸ•·ï¸  å…­è¶³æ©Ÿå™¨äºº PPO + Transformer è¨“ç·´ç¨‹å¼")
    print("=" * 60)

    config = HexapodConfig()

    # === å¯é¸ï¼šèª¿æ•´ç‰¹å®šåƒæ•¸ ===
    # config.learning_rate_start = 1e-4  # ä¿®æ”¹å­¸ç¿’ç‡
    # config.batch_size = 512            # ä¿®æ”¹æ‰¹æ¬¡å¤§å°
    # config.transformer_n_heads = 8     # ä¿®æ”¹æ³¨æ„åŠ›é ­æ•¸
    # config.w_s = 1.5
    
    try:
        # æª¢æŸ¥ GPU ç’°å¢ƒ
        gpu_available = check_gpu_requirements()
        
        # å„ªåŒ– GPU è¨­å®š
        if gpu_available:
            optimize_gpu_settings()
        
        # å‰µå»ºä¸¦é‹è¡Œæ§åˆ¶å™¨
        controller = WebotsPPOController(config)
        
        # é¡¯ç¤º TensorBoard ä½¿ç”¨èªªæ˜
        print(f"\nğŸ“Š TensorBoard ä½¿ç”¨èªªæ˜:")
        print("1. è¨“ç·´é–‹å§‹å¾Œï¼Œé–‹å•Ÿæ–°çš„å‘½ä»¤åˆ—è¦–çª—")
        print(f"2. åŸ·è¡Œ: tensorboard --logdir=./tensorboard_logs/{controller.training_folder}")
        print("3. åœ¨ç€è¦½å™¨é–‹å•Ÿ: http://localhost:6006")
        print("4. å³å¯å³æ™‚ç›£æ§è¨“ç·´é€²åº¦ï¼")
        print(f"ğŸ“ æœ¬æ¬¡è¨“ç·´è³‡æ–™å¤¾: {controller.training_folder}")
        print("   â€¢ Environment/Avg_* - Episodeå¹³å‡å€¼")
        print("   â€¢ Environment/Avg_Distance_From_Origin - èˆ‡åŸé»è·é›¢")
        print("   â€¢ Environment/Avg_Abs_Roll/Pitch - çµ•å°å€¼å§¿æ…‹è§’")
        print("   â€¢ Reward/* - çå‹µæˆåˆ†åˆ†è§£")
        print("   â€¢ Environment/Platform_Angle - éš¨æ©Ÿå¹³å°è§’åº¦")
        print("-" * 60)
        
        controller.run()
        
    except Exception as e:
        print(f"âŒ æ§åˆ¶å™¨é‹è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
    
    print("ğŸ‘‹ ç¨‹å¼çµæŸ")


# ç¨‹å¼å…¥å£é»
if __name__ == "__main__":
    print("ğŸ¯ é‹è¡Œæ¨¡å¼: è¨“ç·´å°ˆç”¨")
    main()